        -:    0:Source:thread.c
        -:    0:Graph:thread.gcno
        -:    0:Data:thread.gcda
        -:    0:Runs:167
        -:    0:Programs:1
        -:    1:/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */
        -:    2:/*
        -:    3: * Thread management for memcached.
        -:    4: */
        -:    5:#include "memcached.h"
        -:    6:#include <assert.h>
        -:    7:#include <stdio.h>
        -:    8:#include <errno.h>
        -:    9:#include <stdlib.h>
        -:   10:#include <string.h>
        -:   11:#include <pthread.h>
        -:   12:
        -:   13:#ifdef __sun
        -:   14:#include <atomic.h>
        -:   15:#endif
        -:   16:
        -:   17:#define ITEMS_PER_ALLOC 64
        -:   18:
        -:   19:/* An item in the connection queue. */
        -:   20:typedef struct conn_queue_item CQ_ITEM;
        -:   21:struct conn_queue_item {
        -:   22:    int               sfd;
        -:   23:    enum conn_states  init_state;
        -:   24:    int               event_flags;
        -:   25:    int               read_buffer_size;
        -:   26:    enum network_transport     transport;
        -:   27:    CQ_ITEM          *next;
        -:   28:};
        -:   29:
        -:   30:/* A connection queue. */
        -:   31:typedef struct conn_queue CQ;
        -:   32:struct conn_queue {
        -:   33:    CQ_ITEM *head;
        -:   34:    CQ_ITEM *tail;
        -:   35:    pthread_mutex_t lock;
        -:   36:};
        -:   37:
        -:   38:/* Locks for cache LRU operations */
        -:   39:pthread_mutex_t lru_locks[POWER_LARGEST];
        -:   40:
        -:   41:/* Connection lock around accepting new connections */
        -:   42:pthread_mutex_t conn_lock = PTHREAD_MUTEX_INITIALIZER;
        -:   43:
        -:   44:#if !defined(HAVE_GCC_ATOMICS) && !defined(__sun)
        -:   45:pthread_mutex_t atomics_mutex = PTHREAD_MUTEX_INITIALIZER;
        -:   46:#endif
        -:   47:
        -:   48:/* Lock for global stats */
        -:   49:static pthread_mutex_t stats_lock = PTHREAD_MUTEX_INITIALIZER;
        -:   50:
        -:   51:/* Lock to cause worker threads to hang up after being woken */
        -:   52:static pthread_mutex_t worker_hang_lock;
        -:   53:
        -:   54:/* Free list of CQ_ITEM structs */
        -:   55:static CQ_ITEM *cqi_freelist;
        -:   56:static pthread_mutex_t cqi_freelist_lock;
        -:   57:
        -:   58:static pthread_mutex_t *item_locks;
        -:   59:/* size of the item lock hash table */
        -:   60:static uint32_t item_lock_count;
        -:   61:unsigned int item_lock_hashpower;
        -:   62:#define hashsize(n) ((unsigned long int)1<<(n))
        -:   63:#define hashmask(n) (hashsize(n)-1)
        -:   64:
        -:   65:static LIBEVENT_DISPATCHER_THREAD dispatcher_thread;
        -:   66:
        -:   67:/*
        -:   68: * Each libevent instance has a wakeup pipe, which other threads
        -:   69: * can use to signal that they've put a new connection on its queue.
        -:   70: */
        -:   71:static LIBEVENT_THREAD *threads;
        -:   72:
        -:   73:/*
        -:   74: * Number of worker threads that have finished setting themselves up.
        -:   75: */
        -:   76:static int init_count = 0;
        -:   77:static pthread_mutex_t init_lock;
        -:   78:static pthread_cond_t init_cond;
        -:   79:
        -:   80:
        -:   81:static void thread_libevent_process(int fd, short which, void *arg);
        -:   82:
   173029:   83:unsigned short refcount_incr(unsigned short *refcount) {
        -:   84:#ifdef HAVE_GCC_ATOMICS
   173029:   85:    return __sync_add_and_fetch(refcount, 1);
        -:   86:#elif defined(__sun)
        -:   87:    return atomic_inc_ushort_nv(refcount);
        -:   88:#else
        -:   89:    unsigned short res;
        -:   90:    mutex_lock(&atomics_mutex);
        -:   91:    (*refcount)++;
        -:   92:    res = *refcount;
        -:   93:    mutex_unlock(&atomics_mutex);
        -:   94:    return res;
        -:   95:#endif
        -:   96:}
        -:   97:
   210578:   98:unsigned short refcount_decr(unsigned short *refcount) {
        -:   99:#ifdef HAVE_GCC_ATOMICS
   210578:  100:    return __sync_sub_and_fetch(refcount, 1);
        -:  101:#elif defined(__sun)
        -:  102:    return atomic_dec_ushort_nv(refcount);
        -:  103:#else
        -:  104:    unsigned short res;
        -:  105:    mutex_lock(&atomics_mutex);
        -:  106:    (*refcount)--;
        -:  107:    res = *refcount;
        -:  108:    mutex_unlock(&atomics_mutex);
        -:  109:    return res;
        -:  110:#endif
        -:  111:}
        -:  112:
        -:  113:/* item_lock() must be held for an item before any modifications to either its
        -:  114: * associated hash bucket, or the structure itself.
        -:  115: * LRU modifications must hold the item lock, and the LRU lock.
        -:  116: * LRU's accessing items must item_trylock() before modifying an item.
        -:  117: * Items accessable from an LRU must not be freed or modified
        -:  118: * without first locking and removing from the LRU.
        -:  119: */
        -:  120:
   134133:  121:void item_lock(uint32_t hv) {
   134133:  122:    mutex_lock(&item_locks[hv & hashmask(item_lock_hashpower)]);
   134133:  123:}
        -:  124:
    91202:  125:void *item_trylock(uint32_t hv) {
    91202:  126:    pthread_mutex_t *lock = &item_locks[hv & hashmask(item_lock_hashpower)];
    91202:  127:    if (pthread_mutex_trylock(lock) == 0) {
    91055:  128:        return lock;
        -:  129:    }
        -:  130:    return NULL;
        -:  131:}
        -:  132:
    91055:  133:void item_trylock_unlock(void *lock) {
    91055:  134:    mutex_unlock((pthread_mutex_t *) lock);
    91055:  135:}
        -:  136:
   134133:  137:void item_unlock(uint32_t hv) {
   134133:  138:    mutex_unlock(&item_locks[hv & hashmask(item_lock_hashpower)]);
   134133:  139:}
        -:  140:
        -:  141:static void wait_for_thread_registration(int nthreads) {
      415:  142:    while (init_count < nthreads) {
      332:  143:        pthread_cond_wait(&init_cond, &init_lock);
        -:  144:    }
        -:  145:}
        -:  146:
      332:  147:static void register_thread_initialized(void) {
      332:  148:    pthread_mutex_lock(&init_lock);
      332:  149:    init_count++;
      332:  150:    pthread_cond_signal(&init_cond);
      332:  151:    pthread_mutex_unlock(&init_lock);
        -:  152:    /* Force worker threads to pile up if someone wants us to */
      332:  153:    pthread_mutex_lock(&worker_hang_lock);
      332:  154:    pthread_mutex_unlock(&worker_hang_lock);
      332:  155:}
        -:  156:
        -:  157:/* Must not be called with any deeper locks held */
    #####:  158:void pause_threads(enum pause_thread_types type) {
        -:  159:    char buf[1];
        -:  160:    int i;
        -:  161:
    #####:  162:    buf[0] = 0;
    #####:  163:    switch (type) {
        -:  164:        case PAUSE_ALL_THREADS:
    #####:  165:            slabs_rebalancer_pause();
    #####:  166:            lru_crawler_pause();
    #####:  167:            lru_maintainer_pause();
        -:  168:        case PAUSE_WORKER_THREADS:
    #####:  169:            buf[0] = 'p';
    #####:  170:            pthread_mutex_lock(&worker_hang_lock);
    #####:  171:            break;
        -:  172:        case RESUME_ALL_THREADS:
    #####:  173:            slabs_rebalancer_resume();
    #####:  174:            lru_crawler_resume();
    #####:  175:            lru_maintainer_resume();
        -:  176:        case RESUME_WORKER_THREADS:
    #####:  177:            pthread_mutex_unlock(&worker_hang_lock);
    #####:  178:            break;
        -:  179:        default:
    #####:  180:            fprintf(stderr, "Unknown lock type: %d\n", type);
    #####:  181:            assert(1 == 0);
        -:  182:            break;
        -:  183:    }
        -:  184:
        -:  185:    /* Only send a message if we have one. */
    #####:  186:    if (buf[0] == 0) {
    #####:  187:        return;
        -:  188:    }
        -:  189:
    #####:  190:    pthread_mutex_lock(&init_lock);
    #####:  191:    init_count = 0;
    #####:  192:    for (i = 0; i < settings.num_threads; i++) {
    #####:  193:        if (write(threads[i].notify_send_fd, buf, 1) != 1) {
    #####:  194:            perror("Failed writing to notify pipe");
        -:  195:            /* TODO: This is a fatal problem. Can it ever happen temporarily? */
        -:  196:        }
        -:  197:    }
        -:  198:    wait_for_thread_registration(settings.num_threads);
    #####:  199:    pthread_mutex_unlock(&init_lock);
        -:  200:}
        -:  201:
        -:  202:/*
        -:  203: * Initializes a connection queue.
        -:  204: */
        -:  205:static void cq_init(CQ *cq) {
      332:  206:    pthread_mutex_init(&cq->lock, NULL);
      332:  207:    cq->head = NULL;
      332:  208:    cq->tail = NULL;
        -:  209:}
        -:  210:
        -:  211:/*
        -:  212: * Looks for an item on a connection queue, but doesn't block if there isn't
        -:  213: * one.
        -:  214: * Returns the item, or NULL if no item is available
        -:  215: */
      681:  216:static CQ_ITEM *cq_pop(CQ *cq) {
        -:  217:    CQ_ITEM *item;
        -:  218:
      681:  219:    pthread_mutex_lock(&cq->lock);
      681:  220:    item = cq->head;
      681:  221:    if (NULL != item) {
      681:  222:        cq->head = item->next;
      681:  223:        if (NULL == cq->head)
      388:  224:            cq->tail = NULL;
        -:  225:    }
      681:  226:    pthread_mutex_unlock(&cq->lock);
        -:  227:
      681:  228:    return item;
        -:  229:}
        -:  230:
        -:  231:/*
        -:  232: * Adds an item to a connection queue.
        -:  233: */
      687:  234:static void cq_push(CQ *cq, CQ_ITEM *item) {
      687:  235:    item->next = NULL;
        -:  236:
      687:  237:    pthread_mutex_lock(&cq->lock);
      687:  238:    if (NULL == cq->tail)
      394:  239:        cq->head = item;
        -:  240:    else
      293:  241:        cq->tail->next = item;
      687:  242:    cq->tail = item;
      687:  243:    pthread_mutex_unlock(&cq->lock);
      687:  244:}
        -:  245:
        -:  246:/*
        -:  247: * Returns a fresh connection queue item.
        -:  248: */
      687:  249:static CQ_ITEM *cqi_new(void) {
      687:  250:    CQ_ITEM *item = NULL;
      687:  251:    pthread_mutex_lock(&cqi_freelist_lock);
      687:  252:    if (cqi_freelist) {
      609:  253:        item = cqi_freelist;
      609:  254:        cqi_freelist = item->next;
        -:  255:    }
      687:  256:    pthread_mutex_unlock(&cqi_freelist_lock);
        -:  257:
      687:  258:    if (NULL == item) {
        -:  259:        int i;
        -:  260:
        -:  261:        /* Allocate a bunch of items at once to reduce fragmentation */
       78:  262:        item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC);
       78:  263:        if (NULL == item) {
        -:  264:            STATS_LOCK();
    #####:  265:            stats.malloc_fails++;
        -:  266:            STATS_UNLOCK();
    #####:  267:            return NULL;
        -:  268:        }
        -:  269:
        -:  270:        /*
        -:  271:         * Link together all the new items except the first one
        -:  272:         * (which we'll return to the caller) for placement on
        -:  273:         * the freelist.
        -:  274:         */
     4836:  275:        for (i = 2; i < ITEMS_PER_ALLOC; i++)
     4836:  276:            item[i - 1].next = &item[i];
        -:  277:
       78:  278:        pthread_mutex_lock(&cqi_freelist_lock);
       78:  279:        item[ITEMS_PER_ALLOC - 1].next = cqi_freelist;
       78:  280:        cqi_freelist = &item[1];
       78:  281:        pthread_mutex_unlock(&cqi_freelist_lock);
        -:  282:    }
        -:  283:
      687:  284:    return item;
        -:  285:}
        -:  286:
        -:  287:
        -:  288:/*
        -:  289: * Frees a connection queue item (adds it to the freelist.)
        -:  290: */
      681:  291:static void cqi_free(CQ_ITEM *item) {
      681:  292:    pthread_mutex_lock(&cqi_freelist_lock);
      681:  293:    item->next = cqi_freelist;
      681:  294:    cqi_freelist = item;
      681:  295:    pthread_mutex_unlock(&cqi_freelist_lock);
      681:  296:}
        -:  297:
        -:  298:
        -:  299:/*
        -:  300: * Creates a worker thread.
        -:  301: */
      332:  302:static void create_worker(void *(*func)(void *), void *arg) {
        -:  303:    pthread_attr_t  attr;
        -:  304:    int             ret;
        -:  305:
      332:  306:    pthread_attr_init(&attr);
        -:  307:
      332:  308:    if ((ret = pthread_create(&((LIBEVENT_THREAD*)arg)->thread_id, &attr, func, arg)) != 0) {
    #####:  309:        fprintf(stderr, "Can't create thread: %s\n",
        -:  310:                strerror(ret));
    #####:  311:        exit(1);
        -:  312:    }
      332:  313:}
        -:  314:
        -:  315:/*
        -:  316: * Sets whether or not we accept new connections.
        -:  317: */
    #####:  318:void accept_new_conns(const bool do_accept) {
    #####:  319:    pthread_mutex_lock(&conn_lock);
    #####:  320:    do_accept_new_conns(do_accept);
    #####:  321:    pthread_mutex_unlock(&conn_lock);
    #####:  322:}
        -:  323:/****************************** LIBEVENT THREADS *****************************/
        -:  324:
        -:  325:/*
        -:  326: * Set up a thread's information.
        -:  327: */
      332:  328:static void setup_thread(LIBEVENT_THREAD *me) {
      332:  329:    me->base = event_init();
      332:  330:    if (! me->base) {
    #####:  331:        fprintf(stderr, "Can't allocate event base\n");
    #####:  332:        exit(1);
        -:  333:    }
        -:  334:
        -:  335:    /* Listen for notifications from other threads */
      332:  336:    event_set(&me->notify_event, me->notify_receive_fd,
        -:  337:              EV_READ | EV_PERSIST, thread_libevent_process, me);
      332:  338:    event_base_set(me->base, &me->notify_event);
        -:  339:
      332:  340:    if (event_add(&me->notify_event, 0) == -1) {
    #####:  341:        fprintf(stderr, "Can't monitor libevent notify pipe\n");
    #####:  342:        exit(1);
        -:  343:    }
        -:  344:
      332:  345:    me->new_conn_queue = malloc(sizeof(struct conn_queue));
      332:  346:    if (me->new_conn_queue == NULL) {
    #####:  347:        perror("Failed to allocate memory for connection queue");
    #####:  348:        exit(EXIT_FAILURE);
        -:  349:    }
      332:  350:    cq_init(me->new_conn_queue);
        -:  351:
      332:  352:    if (pthread_mutex_init(&me->stats.mutex, NULL) != 0) {
    #####:  353:        perror("Failed to initialize mutex");
    #####:  354:        exit(EXIT_FAILURE);
        -:  355:    }
        -:  356:
      332:  357:    me->suffix_cache = cache_create("suffix", SUFFIX_SIZE, sizeof(char*),
        -:  358:                                    NULL, NULL);
      332:  359:    if (me->suffix_cache == NULL) {
    #####:  360:        fprintf(stderr, "Failed to create suffix cache\n");
    #####:  361:        exit(EXIT_FAILURE);
        -:  362:    }
      332:  363:}
        -:  364:
        -:  365:/*
        -:  366: * Worker thread: main event loop
        -:  367: */
      332:  368:static void *worker_libevent(void *arg) {
      332:  369:    LIBEVENT_THREAD *me = arg;
        -:  370:
        -:  371:    /* Any per-thread setup can happen here; memcached_thread_init() will block until
        -:  372:     * all threads have finished initializing.
        -:  373:     */
        -:  374:
      332:  375:    register_thread_initialized();
        -:  376:
      332:  377:    event_base_loop(me->base, 0);
    #####:  378:    return NULL;
        -:  379:}
        -:  380:
        -:  381:
        -:  382:/*
        -:  383: * Processes an incoming "handle a new connection" item. This is called when
        -:  384: * input arrives on the libevent wakeup pipe.
        -:  385: */
      681:  386:static void thread_libevent_process(int fd, short which, void *arg) {
      681:  387:    LIBEVENT_THREAD *me = arg;
        -:  388:    CQ_ITEM *item;
        -:  389:    char buf[1];
        -:  390:
      681:  391:    if (read(fd, buf, 1) != 1)
    #####:  392:        if (settings.verbose > 0)
    #####:  393:            fprintf(stderr, "Can't read from libevent pipe\n");
        -:  394:
      681:  395:    switch (buf[0]) {
        -:  396:    case 'c':
      681:  397:    item = cq_pop(me->new_conn_queue);
        -:  398:
      681:  399:    if (NULL != item) {
      681:  400:        conn *c = conn_new(item->sfd, item->init_state, item->event_flags,
        -:  401:                           item->read_buffer_size, item->transport, me->base);
      681:  402:        if (c == NULL) {
    #####:  403:            if (IS_UDP(item->transport)) {
    #####:  404:                fprintf(stderr, "Can't listen for events on UDP socket\n");
    #####:  405:                exit(1);
        -:  406:            } else {
    #####:  407:                if (settings.verbose > 0) {
    #####:  408:                    fprintf(stderr, "Can't listen for events on fd %d\n",
        -:  409:                        item->sfd);
        -:  410:                }
    #####:  411:                close(item->sfd);
        -:  412:            }
        -:  413:        } else {
      681:  414:            c->thread = me;
        -:  415:        }
      681:  416:        cqi_free(item);
        -:  417:    }
        -:  418:        break;
        -:  419:    /* we were told to pause and report in */
        -:  420:    case 'p':
    #####:  421:    register_thread_initialized();
    #####:  422:        break;
        -:  423:    }
      681:  424:}
        -:  425:
        -:  426:/* Which thread we assigned a connection to most recently. */
        -:  427:static int last_thread = -1;
        -:  428:
        -:  429:/*
        -:  430: * Dispatches a new connection to another thread. This is only ever called
        -:  431: * from the main thread, either during initialization (for UDP) or because
        -:  432: * of an incoming connection.
        -:  433: */
      687:  434:void dispatch_conn_new(int sfd, enum conn_states init_state, int event_flags,
        -:  435:                       int read_buffer_size, enum network_transport transport) {
      687:  436:    CQ_ITEM *item = cqi_new();
        -:  437:    char buf[1];
      687:  438:    if (item == NULL) {
    #####:  439:        close(sfd);
        -:  440:        /* given that malloc failed this may also fail, but let's try */
    #####:  441:        fprintf(stderr, "Failed to allocate memory for connection object\n");
      687:  442:        return ;
        -:  443:    }
        -:  444:
      687:  445:    int tid = (last_thread + 1) % settings.num_threads;
        -:  446:
      687:  447:    LIBEVENT_THREAD *thread = threads + tid;
        -:  448:
      687:  449:    last_thread = tid;
        -:  450:
      687:  451:    item->sfd = sfd;
      687:  452:    item->init_state = init_state;
      687:  453:    item->event_flags = event_flags;
      687:  454:    item->read_buffer_size = read_buffer_size;
      687:  455:    item->transport = transport;
        -:  456:
      687:  457:    cq_push(thread->new_conn_queue, item);
        -:  458:
        -:  459:    MEMCACHED_CONN_DISPATCH(sfd, thread->thread_id);
      687:  460:    buf[0] = 'c';
      687:  461:    if (write(thread->notify_send_fd, buf, 1) != 1) {
    #####:  462:        perror("Writing to thread notify pipe");
        -:  463:    }
        -:  464:}
        -:  465:
        -:  466:/*
        -:  467: * Returns true if this is the thread that listens for new TCP connections.
        -:  468: */
    #####:  469:int is_listen_thread() {
    #####:  470:    return pthread_self() == dispatcher_thread.thread_id;
        -:  471:}
        -:  472:
        -:  473:/********************************* ITEM ACCESS *******************************/
        -:  474:
        -:  475:/*
        -:  476: * Allocates a new item.
        -:  477: */
    52967:  478:item *item_alloc(char *key, size_t nkey, int flags, rel_time_t exptime, int nbytes) {
        -:  479:    item *it;
        -:  480:    /* do_item_alloc handles its own locks */
    52967:  481:    it = do_item_alloc(key, nkey, flags, exptime, nbytes, 0);
    52967:  482:    return it;
        -:  483:}
        -:  484:
        -:  485:/*
        -:  486: * Returns an item if it hasn't been marked as expired,
        -:  487: * lazy-expiring as needed.
        -:  488: */
     9919:  489:item *item_get(const char *key, const size_t nkey) {
        -:  490:    item *it;
        -:  491:    uint32_t hv;
     9919:  492:    hv = hash(key, nkey);
     9919:  493:    item_lock(hv);
     9919:  494:    it = do_item_get(key, nkey, hv);
     9919:  495:    item_unlock(hv);
     9919:  496:    return it;
        -:  497:}
        -:  498:
       97:  499:item *item_touch(const char *key, size_t nkey, uint32_t exptime) {
        -:  500:    item *it;
        -:  501:    uint32_t hv;
       97:  502:    hv = hash(key, nkey);
       97:  503:    item_lock(hv);
       97:  504:    it = do_item_touch(key, nkey, exptime, hv);
       97:  505:    item_unlock(hv);
       97:  506:    return it;
        -:  507:}
        -:  508:
        -:  509:/*
        -:  510: * Links an item into the LRU and hashtable.
        -:  511: */
    #####:  512:int item_link(item *item) {
        -:  513:    int ret;
        -:  514:    uint32_t hv;
        -:  515:
    #####:  516:    hv = hash(ITEM_key(item), item->nkey);
    #####:  517:    item_lock(hv);
    #####:  518:    ret = do_item_link(item, hv);
    #####:  519:    item_unlock(hv);
    #####:  520:    return ret;
        -:  521:}
        -:  522:
        -:  523:/*
        -:  524: * Decrements the reference count on an item and adds it to the freelist if
        -:  525: * needed.
        -:  526: */
    61859:  527:void item_remove(item *item) {
        -:  528:    uint32_t hv;
    61859:  529:    hv = hash(ITEM_key(item), item->nkey);
        -:  530:
    61859:  531:    item_lock(hv);
    61859:  532:    do_item_remove(item);
    61859:  533:    item_unlock(hv);
    61859:  534:}
        -:  535:
        -:  536:/*
        -:  537: * Replaces one item with another in the hashtable.
        -:  538: * Unprotected by a mutex lock since the core server does not require
        -:  539: * it to be thread-safe.
        -:  540: */
    19784:  541:int item_replace(item *old_it, item *new_it, const uint32_t hv) {
    19784:  542:    return do_item_replace(old_it, new_it, hv);
        -:  543:}
        -:  544:
        -:  545:/*
        -:  546: * Unlinks an item from the LRU and hashtable.
        -:  547: */
     2523:  548:void item_unlink(item *item) {
        -:  549:    uint32_t hv;
     2523:  550:    hv = hash(ITEM_key(item), item->nkey);
     2523:  551:    item_lock(hv);
     2523:  552:    do_item_unlink(item, hv);
     2523:  553:    item_unlock(hv);
     2523:  554:}
        -:  555:
        -:  556:/*
        -:  557: * Moves an item to the back of the LRU queue.
        -:  558: */
     6390:  559:void item_update(item *item) {
        -:  560:    uint32_t hv;
     6390:  561:    hv = hash(ITEM_key(item), item->nkey);
        -:  562:
     6390:  563:    item_lock(hv);
     6390:  564:    do_item_update(item);
     6390:  565:    item_unlock(hv);
     6390:  566:}
        -:  567:
        -:  568:/*
        -:  569: * Does arithmetic on a numeric item value.
        -:  570: */
      400:  571:enum delta_result_type add_delta(conn *c, const char *key,
        -:  572:                                 const size_t nkey, int incr,
        -:  573:                                 const int64_t delta, char *buf,
        -:  574:                                 uint64_t *cas) {
        -:  575:    enum delta_result_type ret;
        -:  576:    uint32_t hv;
        -:  577:
      400:  578:    hv = hash(key, nkey);
      400:  579:    item_lock(hv);
      400:  580:    ret = do_add_delta(c, key, nkey, incr, delta, buf, cas, hv);
      400:  581:    item_unlock(hv);
      400:  582:    return ret;
        -:  583:}
        -:  584:
        -:  585:/*
        -:  586: * Stores an item in the cache (high level, obeys set/add/replace semantics)
        -:  587: */
    52945:  588:enum store_item_type store_item(item *item, int comm, conn* c) {
        -:  589:    enum store_item_type ret;
        -:  590:    uint32_t hv;
        -:  591:
    52945:  592:    hv = hash(ITEM_key(item), item->nkey);
    52945:  593:    item_lock(hv);
    52945:  594:    ret = do_store_item(item, comm, c, hv);
    52945:  595:    item_unlock(hv);
    52945:  596:    return ret;
        -:  597:}
        -:  598:
        -:  599:/******************************* GLOBAL STATS ******************************/
        -:  600:
   121822:  601:void STATS_LOCK() {
   121822:  602:    pthread_mutex_lock(&stats_lock);
   121821:  603:}
        -:  604:
   121821:  605:void STATS_UNLOCK() {
   121821:  606:    pthread_mutex_unlock(&stats_lock);
   121820:  607:}
        -:  608:
        3:  609:void threadlocal_stats_reset(void) {
        -:  610:    int ii, sid;
       15:  611:    for (ii = 0; ii < settings.num_threads; ++ii) {
       12:  612:        pthread_mutex_lock(&threads[ii].stats.mutex);
        -:  613:
       12:  614:        threads[ii].stats.get_cmds = 0;
       12:  615:        threads[ii].stats.get_misses = 0;
       12:  616:        threads[ii].stats.touch_cmds = 0;
       12:  617:        threads[ii].stats.touch_misses = 0;
       12:  618:        threads[ii].stats.delete_misses = 0;
       12:  619:        threads[ii].stats.incr_misses = 0;
       12:  620:        threads[ii].stats.decr_misses = 0;
       12:  621:        threads[ii].stats.cas_misses = 0;
       12:  622:        threads[ii].stats.bytes_read = 0;
       12:  623:        threads[ii].stats.bytes_written = 0;
       12:  624:        threads[ii].stats.flush_cmds = 0;
       12:  625:        threads[ii].stats.conn_yields = 0;
       12:  626:        threads[ii].stats.auth_cmds = 0;
       12:  627:        threads[ii].stats.auth_errors = 0;
        -:  628:
      780:  629:        for(sid = 0; sid < MAX_NUMBER_OF_SLAB_CLASSES; sid++) {
      768:  630:            threads[ii].stats.slab_stats[sid].set_cmds = 0;
      768:  631:            threads[ii].stats.slab_stats[sid].get_hits = 0;
      768:  632:            threads[ii].stats.slab_stats[sid].touch_hits = 0;
      768:  633:            threads[ii].stats.slab_stats[sid].delete_hits = 0;
      768:  634:            threads[ii].stats.slab_stats[sid].incr_hits = 0;
      768:  635:            threads[ii].stats.slab_stats[sid].decr_hits = 0;
      768:  636:            threads[ii].stats.slab_stats[sid].cas_hits = 0;
      768:  637:            threads[ii].stats.slab_stats[sid].cas_badval = 0;
        -:  638:        }
        -:  639:
       12:  640:        pthread_mutex_unlock(&threads[ii].stats.mutex);
        -:  641:    }
        3:  642:}
        -:  643:
     3851:  644:void threadlocal_stats_aggregate(struct thread_stats *stats) {
        -:  645:    int ii, sid;
        -:  646:
        -:  647:    /* The struct has a mutex, but we can safely set the whole thing
        -:  648:     * to zero since it is unused when aggregating. */
        -:  649:    memset(stats, 0, sizeof(*stats));
        -:  650:
    19255:  651:    for (ii = 0; ii < settings.num_threads; ++ii) {
    15404:  652:        pthread_mutex_lock(&threads[ii].stats.mutex);
        -:  653:
    15404:  654:        stats->get_cmds += threads[ii].stats.get_cmds;
    15404:  655:        stats->get_misses += threads[ii].stats.get_misses;
    15404:  656:        stats->touch_cmds += threads[ii].stats.touch_cmds;
    15404:  657:        stats->touch_misses += threads[ii].stats.touch_misses;
    15404:  658:        stats->delete_misses += threads[ii].stats.delete_misses;
    15404:  659:        stats->decr_misses += threads[ii].stats.decr_misses;
    15404:  660:        stats->incr_misses += threads[ii].stats.incr_misses;
    15404:  661:        stats->cas_misses += threads[ii].stats.cas_misses;
    15404:  662:        stats->bytes_read += threads[ii].stats.bytes_read;
    15404:  663:        stats->bytes_written += threads[ii].stats.bytes_written;
    15404:  664:        stats->flush_cmds += threads[ii].stats.flush_cmds;
    15404:  665:        stats->conn_yields += threads[ii].stats.conn_yields;
    15404:  666:        stats->auth_cmds += threads[ii].stats.auth_cmds;
    15404:  667:        stats->auth_errors += threads[ii].stats.auth_errors;
        -:  668:
  1001260:  669:        for (sid = 0; sid < MAX_NUMBER_OF_SLAB_CLASSES; sid++) {
  1971712:  670:            stats->slab_stats[sid].set_cmds +=
   985856:  671:                threads[ii].stats.slab_stats[sid].set_cmds;
  1971712:  672:            stats->slab_stats[sid].get_hits +=
   985856:  673:                threads[ii].stats.slab_stats[sid].get_hits;
  1971712:  674:            stats->slab_stats[sid].touch_hits +=
   985856:  675:                threads[ii].stats.slab_stats[sid].touch_hits;
  1971712:  676:            stats->slab_stats[sid].delete_hits +=
   985856:  677:                threads[ii].stats.slab_stats[sid].delete_hits;
  1971712:  678:            stats->slab_stats[sid].decr_hits +=
   985856:  679:                threads[ii].stats.slab_stats[sid].decr_hits;
  1971712:  680:            stats->slab_stats[sid].incr_hits +=
   985856:  681:                threads[ii].stats.slab_stats[sid].incr_hits;
  1971712:  682:            stats->slab_stats[sid].cas_hits +=
   985856:  683:                threads[ii].stats.slab_stats[sid].cas_hits;
  1971712:  684:            stats->slab_stats[sid].cas_badval +=
   985856:  685:                threads[ii].stats.slab_stats[sid].cas_badval;
        -:  686:        }
        -:  687:
    15404:  688:        pthread_mutex_unlock(&threads[ii].stats.mutex);
        -:  689:    }
     3851:  690:}
        -:  691:
     3834:  692:void slab_stats_aggregate(struct thread_stats *stats, struct slab_stats *out) {
        -:  693:    int sid;
        -:  694:
     3834:  695:    out->set_cmds = 0;
     3834:  696:    out->get_hits = 0;
     3834:  697:    out->touch_hits = 0;
     3834:  698:    out->delete_hits = 0;
     3834:  699:    out->incr_hits = 0;
     3834:  700:    out->decr_hits = 0;
     3834:  701:    out->cas_hits = 0;
     3834:  702:    out->cas_badval = 0;
        -:  703:
   249210:  704:    for (sid = 0; sid < MAX_NUMBER_OF_SLAB_CLASSES; sid++) {
   245376:  705:        out->set_cmds += stats->slab_stats[sid].set_cmds;
   245376:  706:        out->get_hits += stats->slab_stats[sid].get_hits;
   245376:  707:        out->touch_hits += stats->slab_stats[sid].touch_hits;
   245376:  708:        out->delete_hits += stats->slab_stats[sid].delete_hits;
   245376:  709:        out->decr_hits += stats->slab_stats[sid].decr_hits;
   245376:  710:        out->incr_hits += stats->slab_stats[sid].incr_hits;
   245376:  711:        out->cas_hits += stats->slab_stats[sid].cas_hits;
   245376:  712:        out->cas_badval += stats->slab_stats[sid].cas_badval;
        -:  713:    }
     3834:  714:}
        -:  715:
        -:  716:/*
        -:  717: * Initializes the thread subsystem, creating various worker threads.
        -:  718: *
        -:  719: * nthreads  Number of worker event handler threads to spawn
        -:  720: * main_base Event base for main thread
        -:  721: */
       83:  722:void memcached_thread_init(int nthreads, struct event_base *main_base) {
        -:  723:    int         i;
        -:  724:    int         power;
        -:  725:
    21331:  726:    for (i = 0; i < POWER_LARGEST; i++) {
    21248:  727:        pthread_mutex_init(&lru_locks[i], NULL);
        -:  728:    }
       83:  729:    pthread_mutex_init(&worker_hang_lock, NULL);
        -:  730:
       83:  731:    pthread_mutex_init(&init_lock, NULL);
       83:  732:    pthread_cond_init(&init_cond, NULL);
        -:  733:
       83:  734:    pthread_mutex_init(&cqi_freelist_lock, NULL);
       83:  735:    cqi_freelist = NULL;
        -:  736:
        -:  737:    /* Want a wide lock table, but don't waste memory */
       83:  738:    if (nthreads < 3) {
        -:  739:        power = 10;
       83:  740:    } else if (nthreads < 4) {
        -:  741:        power = 11;
       83:  742:    } else if (nthreads < 5) {
        -:  743:        power = 12;
        -:  744:    } else {
        -:  745:        /* 8192 buckets, and central locks don't scale much past 5 threads */
    #####:  746:        power = 13;
        -:  747:    }
        -:  748:
       83:  749:    if (power >= hashpower) {
    #####:  750:        fprintf(stderr, "Hash table power size (%d) cannot be equal to or less than item lock table (%d)\n", hashpower, power);
    #####:  751:        fprintf(stderr, "Item lock table grows with `-t N` (worker threadcount)\n");
    #####:  752:        fprintf(stderr, "Hash table grows with `-o hashpower=N` \n");
    #####:  753:        exit(1);
        -:  754:    }
        -:  755:
       83:  756:    item_lock_count = hashsize(power);
       83:  757:    item_lock_hashpower = power;
        -:  758:
       83:  759:    item_locks = calloc(item_lock_count, sizeof(pthread_mutex_t));
       83:  760:    if (! item_locks) {
    #####:  761:        perror("Can't allocate item locks");
    #####:  762:        exit(1);
        -:  763:    }
   339968:  764:    for (i = 0; i < item_lock_count; i++) {
   339968:  765:        pthread_mutex_init(&item_locks[i], NULL);
        -:  766:    }
        -:  767:
       83:  768:    threads = calloc(nthreads, sizeof(LIBEVENT_THREAD));
       83:  769:    if (! threads) {
    #####:  770:        perror("Can't allocate thread descriptors");
    #####:  771:        exit(1);
        -:  772:    }
        -:  773:
       83:  774:    dispatcher_thread.base = main_base;
       83:  775:    dispatcher_thread.thread_id = pthread_self();
        -:  776:
      415:  777:    for (i = 0; i < nthreads; i++) {
        -:  778:        int fds[2];
      332:  779:        if (pipe(fds)) {
    #####:  780:            perror("Can't create notify pipe");
    #####:  781:            exit(1);
        -:  782:        }
        -:  783:
      332:  784:        threads[i].notify_receive_fd = fds[0];
      332:  785:        threads[i].notify_send_fd = fds[1];
        -:  786:
      332:  787:        setup_thread(&threads[i]);
        -:  788:        /* Reserve three fds for the libevent base, and two for the pipe */
      332:  789:        stats.reserved_fds += 5;
        -:  790:    }
        -:  791:
        -:  792:    /* Create threads after we've done all the libevent setup. */
      332:  793:    for (i = 0; i < nthreads; i++) {
      332:  794:        create_worker(worker_libevent, &threads[i]);
        -:  795:    }
        -:  796:
        -:  797:    /* Wait for all the threads to set themselves up before returning. */
       83:  798:    pthread_mutex_lock(&init_lock);
        -:  799:    wait_for_thread_registration(nthreads);
       83:  800:    pthread_mutex_unlock(&init_lock);
       83:  801:}
        -:  802:
